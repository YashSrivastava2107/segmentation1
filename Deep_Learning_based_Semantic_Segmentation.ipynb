{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1834160,
          "sourceType": "datasetVersion",
          "datasetId": 333968
        }
      ],
      "dockerImageVersionId": 29856,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Deep Learning based Semantic Segmentation ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashSrivastava2107/segmentation1/blob/main/Deep_Learning_based_Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "#https://www.kaggle.com/datasets/bulentsiyah/semantic-drone-dataset\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'semantic-drone-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F333968%2F1834160%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240324%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240324T132628Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D376bad791b8ec57024eabbbf4fc695ba23820e6c7941d11ce538969fb7f6cec4a935f20035c1b965ba531a9e2b5ae36a54470c1859fe9989bfb75f0cd0604faa3c077c913c5b46eb3591a95344887e4af6f741407a85dada11e1d3f489c3bf6e2b690da9166d1e9b15647a7e8c5cf798b636174aae88618f337da36c61a3a6adcb069f09db31c5183716458777f109e968dc8a678778e1107110b8a351e477900a7295497c7651b25c01c5be6ea71eb18080aa933ab0708a4cb4c1a840b57d433abcfd5c898a64470f58703a572ee47fb09d0c98dc015d5082a1e1a903b943fe45acbfc67f066f55a94ed1b458447bfe793fd9e0a67acf67f2cc29d4caa425ee'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "SkR-j1jspDl4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "ann_img = np.zeros((30,30,3)).astype('uint8')\n",
        "ann_img[ 3 , 4 ] = 1 # this would set the label of pixel 3,4 as 1\n",
        "ann_img[ 0 , 0 ] = 2 # this would set the label of pixel 0,0 as 2\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:13:53.679469Z",
          "iopub.execute_input": "2024-03-24T11:13:53.679772Z",
          "iopub.status.idle": "2024-03-24T11:13:53.852728Z",
          "shell.execute_reply.started": "2024-03-24T11:13:53.679718Z",
          "shell.execute_reply": "2024-03-24T11:13:53.852138Z"
        },
        "trusted": true,
        "id": "nCOwx-JTpDl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After generating the segmentation images, place them in the training/testing folder. Make separate folders for input images and the segmentation images. The file name of the input image and the corresponding segmentation image should be the same. For this tutorial we would be using a data-set which is already prepared. You can download it from here ([Aerial Semantic Segmentation Drone Dataset](https://www.kaggle.com/bulentsiyah/semantic-drone-dataset))."
      ],
      "metadata": {
        "id": "d2d3-kDrpDl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Aerial Semantic Segmentation Drone Dataset](https://www.kaggle.com/bulentsiyah/semantic-drone-dataset)"
      ],
      "metadata": {
        "id": "LzGkF6sPpDl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "original_image = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/001.jpg\"\n",
        "label_image_semantic = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/001.png\"\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 8), constrained_layout=True)\n",
        "\n",
        "axs[0].imshow( Image.open(original_image))\n",
        "axs[0].grid(False)\n",
        "\n",
        "label_image_semantic = Image.open(label_image_semantic)\n",
        "label_image_semantic = np.asarray(label_image_semantic)\n",
        "axs[1].imshow(label_image_semantic)\n",
        "axs[1].grid(False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:13:53.854792Z",
          "iopub.execute_input": "2024-03-24T11:13:53.855112Z",
          "iopub.status.idle": "2024-03-24T11:13:56.777341Z",
          "shell.execute_reply.started": "2024-03-24T11:13:53.855057Z",
          "shell.execute_reply": "2024-03-24T11:13:56.776433Z"
        },
        "trusted": true,
        "id": "SvID3bzhpDl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-segmentation"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-03-24T11:13:56.77923Z",
          "iopub.execute_input": "2024-03-24T11:13:56.779569Z",
          "iopub.status.idle": "2024-03-24T11:14:08.153514Z",
          "shell.execute_reply.started": "2024-03-24T11:13:56.779511Z",
          "shell.execute_reply": "2024-03-24T11:14:08.152621Z"
        },
        "trusted": true,
        "id": "KU56CNThpDl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "Jgo9TmLkpDl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_commit = True\n",
        "\n",
        "epochs = 20\n",
        "if kaggle_commit:\n",
        "    epochs = 5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:14:08.155111Z",
          "iopub.execute_input": "2024-03-24T11:14:08.155349Z",
          "iopub.status.idle": "2024-03-24T11:14:08.160356Z",
          "shell.execute_reply.started": "2024-03-24T11:14:08.155309Z",
          "shell.execute_reply": "2024-03-24T11:14:08.159713Z"
        },
        "trusted": true,
        "id": "QQ-TXKkupDl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_segmentation.models.unet import vgg_unet\n",
        "\n",
        "n_classes = 23 # Aerial Semantic Segmentation Drone Dataset tree, gras, other vegetation, dirt, gravel, rocks, water, paved area, pool, person, dog, car, bicycle, roof, wall, fence, fence-pole, window, door, obstacle\n",
        "model = vgg_unet(n_classes=n_classes ,  input_height=416, input_width=608  )\n",
        "\n",
        "model.train(\n",
        "    train_images =  \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/\",\n",
        "    train_annotations = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/\",\n",
        "    checkpoints_path = \"vgg_unet\" , epochs=epochs\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T11:14:08.163709Z",
          "iopub.execute_input": "2024-03-24T11:14:08.163951Z",
          "iopub.status.idle": "2024-03-24T12:16:07.173534Z",
          "shell.execute_reply.started": "2024-03-24T11:14:08.163903Z",
          "shell.execute_reply": "2024-03-24T12:16:07.172496Z"
        },
        "trusted": true,
        "id": "_gvxtzCupDl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "VYIYN1ArpDmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "input_image = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/001.jpg\"\n",
        "out = model.predict_segmentation(\n",
        "    inp=input_image,\n",
        "    out_fname=\"out.png\"\n",
        ")\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 20), constrained_layout=True)\n",
        "\n",
        "img_orig = Image.open(input_image)\n",
        "axs[0].imshow(img_orig)\n",
        "axs[0].set_title('original image-001.jpg')\n",
        "axs[0].grid(False)\n",
        "\n",
        "axs[1].imshow(out)\n",
        "axs[1].set_title('prediction image-out.png')\n",
        "axs[1].grid(False)\n",
        "\n",
        "validation_image = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/001.png\"\n",
        "axs[2].imshow( Image.open(validation_image))\n",
        "axs[2].set_title('true label image-001.png')\n",
        "axs[2].grid(False)\n",
        "\n",
        "done = time.time()\n",
        "elapsed = done - start"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:07.177453Z",
          "iopub.execute_input": "2024-03-24T12:16:07.177773Z",
          "iopub.status.idle": "2024-03-24T12:16:11.98593Z",
          "shell.execute_reply.started": "2024-03-24T12:16:07.177713Z",
          "shell.execute_reply": "2024-03-24T12:16:11.985056Z"
        },
        "trusted": true,
        "id": "E63kZAu-pDmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(elapsed)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:11.987349Z",
          "iopub.execute_input": "2024-03-24T12:16:11.987779Z",
          "iopub.status.idle": "2024-03-24T12:16:11.994006Z",
          "shell.execute_reply.started": "2024-03-24T12:16:11.987674Z",
          "shell.execute_reply": "2024-03-24T12:16:11.993035Z"
        },
        "trusted": true,
        "id": "a6bN78VwpDmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import keras\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "\n",
        "from types import MethodType\n",
        "import random\n",
        "import six\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:11.995101Z",
          "iopub.execute_input": "2024-03-24T12:16:11.995343Z",
          "iopub.status.idle": "2024-03-24T12:16:12.00622Z",
          "shell.execute_reply.started": "2024-03-24T12:16:11.995304Z",
          "shell.execute_reply": "2024-03-24T12:16:12.005309Z"
        },
        "trusted": true,
        "id": "vkqbBXUZpDmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.007327Z",
          "iopub.execute_input": "2024-03-24T12:16:12.007559Z",
          "iopub.status.idle": "2024-03-24T12:16:12.016259Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.007519Z",
          "shell.execute_reply": "2024-03-24T12:16:12.015542Z"
        },
        "trusted": true,
        "id": "vM5tZ9REpDmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_ORDERING_CHANNELS_FIRST = \"channels_first\"\n",
        "IMAGE_ORDERING_CHANNELS_LAST = \"channels_last\"\n",
        "# Default IMAGE_ORDERING = channels_last\n",
        "IMAGE_ORDERING = IMAGE_ORDERING_CHANNELS_LAST\n",
        "\n",
        "if IMAGE_ORDERING == 'channels_first':\n",
        "    MERGE_AXIS = 1\n",
        "elif IMAGE_ORDERING == 'channels_last':\n",
        "    MERGE_AXIS = -1\n",
        "\n",
        "if IMAGE_ORDERING == 'channels_first':\n",
        "    pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
        "                     \"releases/download/v0.1/\" \\\n",
        "                     \"vgg16_weights_th_dim_ordering_th_kernels_notop.h5\"\n",
        "elif IMAGE_ORDERING == 'channels_last':\n",
        "    pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
        "                     \"releases/download/v0.1/\" \\\n",
        "                     \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "class_colors = [(random.randint(0, 255), random.randint(\n",
        "    0, 255), random.randint(0, 255)) for _ in range(5000)]\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.017621Z",
          "iopub.execute_input": "2024-03-24T12:16:12.017953Z",
          "iopub.status.idle": "2024-03-24T12:16:12.066965Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.017893Z",
          "shell.execute_reply": "2024-03-24T12:16:12.066352Z"
        },
        "trusted": true,
        "id": "PI6t35dBpDmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_colored_segmentation_image( seg_arr  , n_classes , colors=class_colors ):\n",
        "    output_height = seg_arr.shape[0]\n",
        "    output_width = seg_arr.shape[1]\n",
        "\n",
        "    seg_img = np.zeros((output_height, output_width, 3))\n",
        "\n",
        "    for c in range(n_classes):\n",
        "        seg_img[:, :, 0] += ((seg_arr[:, :] == c)*(colors[c][0])).astype('uint8')\n",
        "        seg_img[:, :, 1] += ((seg_arr[:, :] == c)*(colors[c][1])).astype('uint8')\n",
        "        seg_img[:, :, 2] += ((seg_arr[:, :] == c)*(colors[c][2])).astype('uint8')\n",
        "\n",
        "    return seg_img\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.067966Z",
          "iopub.execute_input": "2024-03-24T12:16:12.068204Z",
          "iopub.status.idle": "2024-03-24T12:16:12.076901Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.068158Z",
          "shell.execute_reply": "2024-03-24T12:16:12.076004Z"
        },
        "trusted": true,
        "id": "3X9Wt8gspDmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_segmentation( seg_arr , inp_img=None  , n_classes=None ,\n",
        "    colors=class_colors , class_names=None , overlay_img=False , show_legends=False ,\n",
        "    prediction_width=None , prediction_height=None  ):\n",
        "\n",
        "\n",
        "    if n_classes is None:\n",
        "        n_classes = np.max(seg_arr)\n",
        "\n",
        "    seg_img = get_colored_segmentation_image( seg_arr  , n_classes , colors=colors )\n",
        "\n",
        "    if not inp_img is None:\n",
        "        orininal_h = inp_img.shape[0]\n",
        "        orininal_w = inp_img.shape[1]\n",
        "        seg_img = cv2.resize(seg_img, (orininal_w, orininal_h))\n",
        "\n",
        "\n",
        "    if (not prediction_height is None) and  (not prediction_width is None):\n",
        "        seg_img = cv2.resize(seg_img, (prediction_width, prediction_height ))\n",
        "        if not inp_img is None:\n",
        "            inp_img = cv2.resize(inp_img, (prediction_width, prediction_height ))\n",
        "\n",
        "\n",
        "    if overlay_img:\n",
        "        assert not inp_img is None\n",
        "        seg_img = overlay_seg_image( inp_img , seg_img  )\n",
        "\n",
        "\n",
        "    if show_legends:\n",
        "        assert not class_names is None\n",
        "        legend_img = get_legends(class_names , colors=colors )\n",
        "\n",
        "        seg_img = concat_lenends( seg_img , legend_img )\n",
        "\n",
        "\n",
        "    return seg_img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.078292Z",
          "iopub.execute_input": "2024-03-24T12:16:12.078638Z",
          "iopub.status.idle": "2024-03-24T12:16:12.091642Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.078577Z",
          "shell.execute_reply": "2024-03-24T12:16:12.09087Z"
        },
        "trusted": true,
        "id": "boc73j9ppDmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_array(image_input, width, height, imgNorm=\"sub_mean\",\n",
        "                  ordering='channels_first'):\n",
        "    \"\"\" Load image array from input \"\"\"\n",
        "\n",
        "    if type(image_input) is np.ndarray:\n",
        "        # It is already an array, use it as it is\n",
        "        img = image_input\n",
        "    elif  isinstance(image_input, six.string_types)  :\n",
        "        if not os.path.isfile(image_input):\n",
        "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\".format(image_input))\n",
        "        img = cv2.imread(image_input, 1)\n",
        "    else:\n",
        "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\".format(str(type(image_input))))\n",
        "\n",
        "    if imgNorm == \"sub_and_divide\":\n",
        "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
        "    elif imgNorm == \"sub_mean\":\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        img = img.astype(np.float32)\n",
        "        img[:, :, 0] -= 103.939\n",
        "        img[:, :, 1] -= 116.779\n",
        "        img[:, :, 2] -= 123.68\n",
        "        img = img[:, :, ::-1]\n",
        "    elif imgNorm == \"divide\":\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        img = img.astype(np.float32)\n",
        "        img = img/255.0\n",
        "\n",
        "    if ordering == 'channels_first':\n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "    return img\n",
        "\n",
        "def get_image_arr( path , width , height , imgNorm=\"sub_mean\" , odering='channels_first' ):\n",
        "\n",
        "\tif type( path ) is np.ndarray:\n",
        "\t\timg = path\n",
        "\telse:\n",
        "\t\timg = cv2.imread(path, 1)\n",
        "\n",
        "\tif imgNorm == \"sub_and_divide\":\n",
        "\t\timg = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
        "\telif imgNorm == \"sub_mean\":\n",
        "\t\timg = cv2.resize(img, ( width , height ))\n",
        "\t\timg = img.astype(np.float32)\n",
        "\t\timg[:,:,0] -= 103.939\n",
        "\t\timg[:,:,1] -= 116.779\n",
        "\t\timg[:,:,2] -= 123.68\n",
        "\t\timg = img[ : , : , ::-1 ]\n",
        "\telif imgNorm == \"divide\":\n",
        "\t\timg = cv2.resize(img, ( width , height ))\n",
        "\t\timg = img.astype(np.float32)\n",
        "\t\timg = img/255.0\n",
        "\n",
        "\tif odering == 'channels_first':\n",
        "\t\timg = np.rollaxis(img, 2, 0)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def get_segmentation_array(image_input, nClasses, width, height, no_reshape=False):\n",
        "    \"\"\" Load segmentation array from input \"\"\"\n",
        "\n",
        "    seg_labels = np.zeros((height, width, nClasses))\n",
        "\n",
        "    if type(image_input) is np.ndarray:\n",
        "        # It is already an array, use it as it is\n",
        "        img = image_input\n",
        "    elif isinstance(image_input, six.string_types) :\n",
        "        if not os.path.isfile(image_input):\n",
        "            raise DataLoaderError(\"get_segmentation_array: path {0} doesn't exist\".format(image_input))\n",
        "        img = cv2.imread(image_input, 1)\n",
        "    else:\n",
        "        raise DataLoaderError(\"get_segmentation_array: Can't process input type {0}\".format(str(type(image_input))))\n",
        "\n",
        "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "    img = img[:, :, 0]\n",
        "\n",
        "    for c in range(nClasses):\n",
        "        seg_labels[:, :, c] = (img == c).astype(int)\n",
        "\n",
        "    if not no_reshape:\n",
        "        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n",
        "\n",
        "    return seg_labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.092787Z",
          "iopub.execute_input": "2024-03-24T12:16:12.092994Z",
          "iopub.status.idle": "2024-03-24T12:16:12.11978Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.092962Z",
          "shell.execute_reply": "2024-03-24T12:16:12.118833Z"
        },
        "trusted": true,
        "id": "y4qiXWlSpDmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_segmentation_generator(images_path, segs_path, batch_size,\n",
        "                                 n_classes, input_height, input_width,\n",
        "                                 output_height, output_width,\n",
        "                                 do_augment=False ,augmentation_name=\"aug_all\" ):\n",
        "\n",
        "    img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
        "    random.shuffle(img_seg_pairs)\n",
        "    zipped = itertools.cycle(img_seg_pairs)\n",
        "\n",
        "    while True:\n",
        "        X = []\n",
        "        Y = []\n",
        "        for _ in range(batch_size):\n",
        "            im, seg = next(zipped)\n",
        "\n",
        "            im = cv2.imread(im, 1)\n",
        "            seg = cv2.imread(seg, 1)\n",
        "\n",
        "            if do_augment:\n",
        "                im, seg[:, :, 0] = augment_seg(im, seg[:, :, 0] , augmentation_name=augmentation_name )\n",
        "\n",
        "            X.append(get_image_array(im, input_width,\n",
        "                                   input_height, ordering=IMAGE_ORDERING))\n",
        "            Y.append(get_segmentation_array(\n",
        "                seg, n_classes, output_width, output_height))\n",
        "\n",
        "        yield np.array(X), np.array(Y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.121157Z",
          "iopub.execute_input": "2024-03-24T12:16:12.12149Z",
          "iopub.status.idle": "2024-03-24T12:16:12.133979Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.121418Z",
          "shell.execute_reply": "2024-03-24T12:16:12.133242Z"
        },
        "trusted": true,
        "id": "-W73mPtRpDmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False):\n",
        "    \"\"\" Find all the images from the images_path directory and\n",
        "        the segmentation images from the segs_path directory\n",
        "        while checking integrity of data \"\"\"\n",
        "\n",
        "    ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\" , \".bmp\"]\n",
        "    ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\", \".bmp\"]\n",
        "\n",
        "    image_files = []\n",
        "    segmentation_files = {}\n",
        "\n",
        "    for dir_entry in os.listdir(images_path):\n",
        "        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n",
        "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
        "            file_name, file_extension = os.path.splitext(dir_entry)\n",
        "            image_files.append((file_name, file_extension, os.path.join(images_path, dir_entry)))\n",
        "\n",
        "    for dir_entry in os.listdir(segs_path):\n",
        "        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n",
        "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n",
        "            file_name, file_extension = os.path.splitext(dir_entry)\n",
        "            if file_name in segmentation_files:\n",
        "                raise DataLoaderError(\"Segmentation file with filename {0} already exists and is ambiguous to resolve with path {1}. Please remove or rename the latter.\".format(file_name, os.path.join(segs_path, dir_entry)))\n",
        "            segmentation_files[file_name] = (file_extension, os.path.join(segs_path, dir_entry))\n",
        "\n",
        "    return_value = []\n",
        "    # Match the images and segmentations\n",
        "    for image_file, _, image_full_path in image_files:\n",
        "        if image_file in segmentation_files:\n",
        "            return_value.append((image_full_path, segmentation_files[image_file][1]))\n",
        "        elif ignore_non_matching:\n",
        "            continue\n",
        "        else:\n",
        "            # Error out\n",
        "            raise DataLoaderError(\"No corresponding segmentation found for image {0}.\".format(image_full_path))\n",
        "\n",
        "    return return_value"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.135135Z",
          "iopub.execute_input": "2024-03-24T12:16:12.135383Z",
          "iopub.status.idle": "2024-03-24T12:16:12.148847Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.135337Z",
          "shell.execute_reply": "2024-03-24T12:16:12.148204Z"
        },
        "trusted": true,
        "id": "GzrDQUEApDmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_segmentation_dataset(images_path, segs_path, n_classes, show_all_errors=False):\n",
        "    try:\n",
        "        img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
        "        if not len(img_seg_pairs):\n",
        "            print(\"Couldn't load any data from images_path: {0} and segmentations path: {1}\".format(images_path, segs_path))\n",
        "            return False\n",
        "\n",
        "        return_value = True\n",
        "        for im_fn, seg_fn in tqdm(img_seg_pairs):\n",
        "            img = cv2.imread(im_fn)\n",
        "            seg = cv2.imread(seg_fn)\n",
        "            # Check dimensions match\n",
        "            if not img.shape == seg.shape:\n",
        "                return_value = False\n",
        "                print(\"The size of image {0} and its segmentation {1} doesn't match (possibly the files are corrupt).\".format(im_fn, seg_fn))\n",
        "                if not show_all_errors:\n",
        "                    break\n",
        "            else:\n",
        "                max_pixel_value = np.max(seg[:, :, 0])\n",
        "                if max_pixel_value >= n_classes:\n",
        "                    return_value = False\n",
        "                    print(\"The pixel values of the segmentation image {0} violating range [0, {1}]. Found maximum pixel value {2}\".format(seg_fn, str(n_classes - 1), max_pixel_value))\n",
        "                    if not show_all_errors:\n",
        "                        break\n",
        "        if return_value:\n",
        "            print(\"Dataset verified! \")\n",
        "        else:\n",
        "            print(\"Dataset not verified!\")\n",
        "        return return_value\n",
        "    except Exception as e:\n",
        "        print(\"Found error during data loading\\n{0}\".format(str(e)))\n",
        "        return False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.150057Z",
          "iopub.execute_input": "2024-03-24T12:16:12.150297Z",
          "iopub.status.idle": "2024-03-24T12:16:12.163615Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.150239Z",
          "shell.execute_reply": "2024-03-24T12:16:12.162996Z"
        },
        "trusted": true,
        "id": "bZprveEFpDmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate( model=None , inp_images=None , annotations=None,inp_images_dir=None ,annotations_dir=None , checkpoints_path=None ):\n",
        "\n",
        "    if model is None:\n",
        "        assert (checkpoints_path is not None) , \"Please provide the model or the checkpoints_path\"\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    if inp_images is None:\n",
        "        assert (inp_images_dir is not None) , \"Please privide inp_images or inp_images_dir\"\n",
        "        assert (annotations_dir is not None) , \"Please privide inp_images or inp_images_dir\"\n",
        "\n",
        "        paths = get_pairs_from_paths(inp_images_dir , annotations_dir )\n",
        "        paths = list(zip(*paths))\n",
        "        inp_images = list(paths[0])\n",
        "        annotations = list(paths[1])\n",
        "\n",
        "    assert type(inp_images) is list\n",
        "    assert type(annotations) is list\n",
        "\n",
        "    tp = np.zeros( model.n_classes  )\n",
        "    fp = np.zeros( model.n_classes  )\n",
        "    fn = np.zeros( model.n_classes  )\n",
        "    n_pixels = np.zeros( model.n_classes  )\n",
        "\n",
        "    for inp , ann   in tqdm( zip( inp_images , annotations )):\n",
        "        pr = predict(model , inp )\n",
        "        gt = get_segmentation_array( ann , model.n_classes ,  model.output_width , model.output_height , no_reshape=True  )\n",
        "        gt = gt.argmax(-1)\n",
        "        pr = pr.flatten()\n",
        "        gt = gt.flatten()\n",
        "\n",
        "        for cl_i in range(model.n_classes ):\n",
        "\n",
        "            tp[ cl_i ] += np.sum( (pr == cl_i) * (gt == cl_i) )\n",
        "            fp[ cl_i ] += np.sum( (pr == cl_i) * ((gt != cl_i)) )\n",
        "            fn[ cl_i ] += np.sum( (pr != cl_i) * ((gt == cl_i)) )\n",
        "            n_pixels[ cl_i ] += np.sum( gt == cl_i  )\n",
        "\n",
        "    cl_wise_score = tp / ( tp + fp + fn + 0.000000000001 )\n",
        "    n_pixels_norm = n_pixels /  np.sum(n_pixels)\n",
        "    frequency_weighted_IU = np.sum(cl_wise_score*n_pixels_norm)\n",
        "    mean_IU = np.mean(cl_wise_score)\n",
        "    return {\"frequency_weighted_IU\":frequency_weighted_IU , \"mean_IU\":mean_IU , \"class_wise_IU\":cl_wise_score }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.164879Z",
          "iopub.execute_input": "2024-03-24T12:16:12.165136Z",
          "iopub.status.idle": "2024-03-24T12:16:12.182455Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.16509Z",
          "shell.execute_reply": "2024-03-24T12:16:12.181696Z"
        },
        "trusted": true,
        "id": "1wAew_zGpDmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_multiple(model=None, inps=None, inp_dir=None, out_dir=None,\n",
        "                     checkpoints_path=None ,overlay_img=False ,\n",
        "    class_names=None , show_legends=False , colors=class_colors , prediction_width=None , prediction_height=None  ):\n",
        "\n",
        "    if model is None and (checkpoints_path is not None):\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    if inps is None and (inp_dir is not None):\n",
        "        inps = glob.glob(os.path.join(inp_dir, \"*.jpg\")) + glob.glob(\n",
        "            os.path.join(inp_dir, \"*.png\")) + \\\n",
        "            glob.glob(os.path.join(inp_dir, \"*.jpeg\"))\n",
        "\n",
        "    assert type(inps) is list\n",
        "\n",
        "    all_prs = []\n",
        "\n",
        "    for i, inp in enumerate(tqdm(inps)):\n",
        "        if out_dir is None:\n",
        "            out_fname = None\n",
        "        else:\n",
        "            if isinstance(inp, six.string_types):\n",
        "                out_fname = os.path.join(out_dir, os.path.basename(inp))\n",
        "            else:\n",
        "                out_fname = os.path.join(out_dir, str(i) + \".jpg\")\n",
        "\n",
        "        pr = predict( model, inp, out_fname ,\n",
        "            overlay_img=overlay_img,class_names=class_names ,show_legends=show_legends ,\n",
        "            colors=colors , prediction_width=prediction_width , prediction_height=prediction_height  )\n",
        "\n",
        "        all_prs.append(pr)\n",
        "\n",
        "    return all_prs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.183579Z",
          "iopub.execute_input": "2024-03-24T12:16:12.183879Z",
          "iopub.status.idle": "2024-03-24T12:16:12.196473Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.183832Z",
          "shell.execute_reply": "2024-03-24T12:16:12.195723Z"
        },
        "trusted": true,
        "id": "2SDXKo-wpDmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model=None, inp=None, out_fname=None, checkpoints_path=None,overlay_img=False ,\n",
        "    class_names=None , show_legends=False , colors=class_colors , prediction_width=None , prediction_height=None  ):\n",
        "\n",
        "    if model is None and (checkpoints_path is not None):\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    assert (inp is not None)\n",
        "    assert((type(inp) is np.ndarray) or isinstance(inp, six.string_types)\n",
        "           ), \"Inupt should be the CV image or the input file name\"\n",
        "\n",
        "    if isinstance(inp, six.string_types):\n",
        "        inp = cv2.imread(inp)\n",
        "\n",
        "    assert len(inp.shape) == 3, \"Image should be h,w,3 \"\n",
        "    orininal_h = inp.shape[0]\n",
        "    orininal_w = inp.shape[1]\n",
        "\n",
        "    output_width = model.output_width\n",
        "    output_height = model.output_height\n",
        "    input_width = model.input_width\n",
        "    input_height = model.input_height\n",
        "    n_classes = model.n_classes\n",
        "\n",
        "    x = get_image_array(inp, input_width, input_height, ordering=IMAGE_ORDERING)\n",
        "    pr = model.predict(np.array([x]))[0]\n",
        "    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n",
        "\n",
        "    seg_img = visualize_segmentation( pr , inp ,n_classes=n_classes , colors=colors\n",
        "        , overlay_img=overlay_img ,show_legends=show_legends ,class_names=class_names ,prediction_width=prediction_width , prediction_height=prediction_height   )\n",
        "\n",
        "    if out_fname is not None:\n",
        "        cv2.imwrite(out_fname, seg_img)\n",
        "\n",
        "    return pr\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.197794Z",
          "iopub.execute_input": "2024-03-24T12:16:12.198198Z",
          "iopub.status.idle": "2024-03-24T12:16:12.211457Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.198003Z",
          "shell.execute_reply": "2024-03-24T12:16:12.210747Z"
        },
        "trusted": true,
        "id": "aRtrktq8pDmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          train_images,\n",
        "          train_annotations,\n",
        "          input_height=None,\n",
        "          input_width=None,\n",
        "          n_classes=None,\n",
        "          verify_dataset=True,\n",
        "          checkpoints_path=None,\n",
        "          epochs=5,\n",
        "          batch_size=2,\n",
        "          validate=False,\n",
        "          val_images=None,\n",
        "          val_annotations=None,\n",
        "          val_batch_size=2,\n",
        "          auto_resume_checkpoint=False,\n",
        "          load_weights=None,\n",
        "          steps_per_epoch=512,\n",
        "          val_steps_per_epoch=512,\n",
        "          gen_use_multiprocessing=False,\n",
        "          ignore_zero_class=False ,\n",
        "          optimizer_name='adadelta' , do_augment=False , augmentation_name=\"aug_all\"\n",
        "          ):\n",
        "\n",
        "\n",
        "    # check if user gives model name instead of the model object\n",
        "    if isinstance(model, six.string_types):\n",
        "        # create the model from the name\n",
        "        assert (n_classes is not None), \"Please provide the n_classes\"\n",
        "        if (input_height is not None) and (input_width is not None):\n",
        "            model = model_from_name[model](\n",
        "                n_classes, input_height=input_height, input_width=input_width)\n",
        "        else:\n",
        "            model = model_from_name[model](n_classes)\n",
        "\n",
        "    n_classes = model.n_classes\n",
        "    input_height = model.input_height\n",
        "    input_width = model.input_width\n",
        "    output_height = model.output_height\n",
        "    output_width = model.output_width\n",
        "\n",
        "    if validate:\n",
        "        assert val_images is not None\n",
        "        assert val_annotations is not None\n",
        "\n",
        "    if optimizer_name is not None:\n",
        "\n",
        "        if ignore_zero_class:\n",
        "            loss_k = masked_categorical_crossentropy\n",
        "        else:\n",
        "            loss_k = 'categorical_crossentropy'\n",
        "\n",
        "        model.compile(loss= loss_k ,\n",
        "                      optimizer=optimizer_name,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    if checkpoints_path is not None:\n",
        "        with open(checkpoints_path+\"_config.json\", \"w\") as f:\n",
        "            json.dump({\n",
        "                \"model_class\": model.model_name,\n",
        "                \"n_classes\": n_classes,\n",
        "                \"input_height\": input_height,\n",
        "                \"input_width\": input_width,\n",
        "                \"output_height\": output_height,\n",
        "                \"output_width\": output_width\n",
        "            }, f)\n",
        "\n",
        "    if load_weights is not None and len(load_weights) > 0:\n",
        "        print(\"Loading weights from \", load_weights)\n",
        "        model.load_weights(load_weights)\n",
        "\n",
        "    if auto_resume_checkpoint and (checkpoints_path is not None):\n",
        "        latest_checkpoint = find_latest_checkpoint(checkpoints_path)\n",
        "        if latest_checkpoint is not None:\n",
        "            print(\"Loading the weights from latest checkpoint \",\n",
        "                  latest_checkpoint)\n",
        "            model.load_weights(latest_checkpoint)\n",
        "\n",
        "    if verify_dataset:\n",
        "        print(\"Verifying training dataset\")\n",
        "        verified = verify_segmentation_dataset(train_images, train_annotations, n_classes)\n",
        "        assert verified\n",
        "        if validate:\n",
        "            print(\"Verifying validation dataset\")\n",
        "            verified = verify_segmentation_dataset(val_images, val_annotations, n_classes)\n",
        "            assert verified\n",
        "\n",
        "    train_gen = image_segmentation_generator(\n",
        "        train_images, train_annotations,  batch_size,  n_classes,\n",
        "        input_height, input_width, output_height, output_width , do_augment=do_augment ,augmentation_name=augmentation_name )\n",
        "\n",
        "    if validate:\n",
        "        val_gen = image_segmentation_generator(\n",
        "            val_images, val_annotations,  val_batch_size,\n",
        "            n_classes, input_height, input_width, output_height, output_width)\n",
        "\n",
        "    if not validate:\n",
        "        for ep in range(epochs):\n",
        "            print(\"Starting Epoch \", ep)\n",
        "            model.fit_generator(train_gen, steps_per_epoch, epochs=1, use_multiprocessing=True)\n",
        "            if checkpoints_path is not None:\n",
        "                model.save_weights(checkpoints_path + \".\" + str(ep))\n",
        "                print(\"saved \", checkpoints_path + \".model.\" + str(ep))\n",
        "            print(\"Finished Epoch\", ep)\n",
        "    else:\n",
        "        for ep in range(epochs):\n",
        "            print(\"Starting Epoch \", ep)\n",
        "            model.fit_generator(train_gen, steps_per_epoch,\n",
        "                                validation_data=val_gen,\n",
        "                                validation_steps=val_steps_per_epoch,  epochs=1 , use_multiprocessing=gen_use_multiprocessing)\n",
        "            if checkpoints_path is not None:\n",
        "                model.save_weights(checkpoints_path + \".\" + str(ep))\n",
        "                print(\"saved \", checkpoints_path + \".model.\" + str(ep))\n",
        "            print(\"Finished Epoch\", ep)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.212763Z",
          "iopub.execute_input": "2024-03-24T12:16:12.213006Z",
          "iopub.status.idle": "2024-03-24T12:16:12.239456Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.212941Z",
          "shell.execute_reply": "2024-03-24T12:16:12.238807Z"
        },
        "trusted": true,
        "id": "q9Z1zoyipDmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segmentation_model(input, output):\n",
        "\n",
        "    img_input = input\n",
        "    o = output\n",
        "\n",
        "    o_shape = Model(img_input, o).output_shape\n",
        "    i_shape = Model(img_input, o).input_shape\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        output_height = o_shape[2]\n",
        "        output_width = o_shape[3]\n",
        "        input_height = i_shape[2]\n",
        "        input_width = i_shape[3]\n",
        "        n_classes = o_shape[1]\n",
        "        o = (Reshape((-1, output_height*output_width)))(o)\n",
        "        o = (Permute((2, 1)))(o)\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        output_height = o_shape[1]\n",
        "        output_width = o_shape[2]\n",
        "        input_height = i_shape[1]\n",
        "        input_width = i_shape[2]\n",
        "        n_classes = o_shape[3]\n",
        "        o = (Reshape((output_height*output_width, -1)))(o)\n",
        "\n",
        "    o = (Activation('softmax'))(o)\n",
        "    model = Model(img_input, o)\n",
        "    model.output_width = output_width\n",
        "    model.output_height = output_height\n",
        "    model.n_classes = n_classes\n",
        "    model.input_height = input_height\n",
        "    model.input_width = input_width\n",
        "    model.model_name = \"\"\n",
        "\n",
        "    model.train = MethodType(train, model)\n",
        "    model.predict_segmentation = MethodType(predict, model)\n",
        "    model.predict_multiple = MethodType(predict_multiple, model)\n",
        "    model.evaluate_segmentation = MethodType(evaluate, model)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.240473Z",
          "iopub.execute_input": "2024-03-24T12:16:12.240742Z",
          "iopub.status.idle": "2024-03-24T12:16:12.253651Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.240691Z",
          "shell.execute_reply": "2024-03-24T12:16:12.252736Z"
        },
        "trusted": true,
        "id": "eOPv3DDRpDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vgg_encoder(input_height=224,  input_width=224, pretrained='imagenet'):\n",
        "\n",
        "    assert input_height % 32 == 0\n",
        "    assert input_width % 32 == 0\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        img_input = Input(shape=(3, input_height, input_width))\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        img_input = Input(shape=(input_height, input_width, 3))\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               name='block1_conv1', data_format=IMAGE_ORDERING)(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f1 = x\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "               name='block2_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f2 = x\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "               name='block3_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f3 = x\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block4_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f4 = x\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block5_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f5 = x\n",
        "\n",
        "    if pretrained == 'imagenet':\n",
        "        VGG_Weights_path = keras.utils.get_file(pretrained_url.split(\"/\")[-1], pretrained_url)\n",
        "        Model(img_input, x).load_weights(VGG_Weights_path)\n",
        "\n",
        "    return img_input, [f1, f2, f3, f4, f5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.255112Z",
          "iopub.execute_input": "2024-03-24T12:16:12.255414Z",
          "iopub.status.idle": "2024-03-24T12:16:12.281Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.25536Z",
          "shell.execute_reply": "2024-03-24T12:16:12.28029Z"
        },
        "trusted": true,
        "id": "Y-TEFbkopDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
        "          input_width=608):\n",
        "\n",
        "    img_input, levels = encoder(\n",
        "        input_height=input_height, input_width=input_width)\n",
        "    [f1, f2, f3, f4, f5] = levels\n",
        "\n",
        "    o = f4\n",
        "\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (concatenate([o, f3], axis=MERGE_AXIS))\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (concatenate([o, f2], axis=MERGE_AXIS))\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
        "\n",
        "    if l1_skip_conn:\n",
        "        o = (concatenate([o, f1], axis=MERGE_AXIS))\n",
        "\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = Conv2D(n_classes, (3, 3), padding='same',data_format=IMAGE_ORDERING)(o)\n",
        "\n",
        "    model = get_segmentation_model(img_input, o)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.282235Z",
          "iopub.execute_input": "2024-03-24T12:16:12.282491Z",
          "iopub.status.idle": "2024-03-24T12:16:12.29927Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.282447Z",
          "shell.execute_reply": "2024-03-24T12:16:12.298496Z"
        },
        "trusted": true,
        "id": "hiaG5f2tpDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3):\n",
        "\n",
        "    model = _unet(n_classes, get_vgg_encoder,input_height=input_height, input_width=input_width)\n",
        "    model.model_name = \"vgg_unet\"\n",
        "    return model\n",
        "\n",
        "n_classes = 23 # Aerial Semantic Segmentation Drone Dataset tree, gras, other vegetation, dirt, gravel, rocks, water, paved area, pool, person, dog, car, bicycle, roof, wall, fence, fence-pole, window, door, obstacle\n",
        "\n",
        "model = vgg_unet(n_classes=n_classes,  input_height=416, input_width=608)\n",
        "model_from_name = {}\n",
        "model_from_name[\"vgg_unet\"] = vgg_unet\n",
        "\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.300346Z",
          "iopub.execute_input": "2024-03-24T12:16:12.300596Z",
          "iopub.status.idle": "2024-03-24T12:16:12.714732Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.300551Z",
          "shell.execute_reply": "2024-03-24T12:16:12.713835Z"
        },
        "trusted": true,
        "id": "jJnxByPBpDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "f8q3SeIlpDmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_commit = True\n",
        "\n",
        "epochs = 20\n",
        "if kaggle_commit:\n",
        "    epochs = 5\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.715923Z",
          "iopub.execute_input": "2024-03-24T12:16:12.716153Z",
          "iopub.status.idle": "2024-03-24T12:16:12.719922Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.716114Z",
          "shell.execute_reply": "2024-03-24T12:16:12.719263Z"
        },
        "trusted": true,
        "id": "kjP34wbKpDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(\n",
        "    train_images =  \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/\",\n",
        "    train_annotations = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/\",\n",
        "    checkpoints_path = \"vgg_unet\" , epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T12:16:12.721008Z",
          "iopub.execute_input": "2024-03-24T12:16:12.721223Z",
          "iopub.status.idle": "2024-03-24T13:22:16.64149Z",
          "shell.execute_reply.started": "2024-03-24T12:16:12.721186Z",
          "shell.execute_reply": "2024-03-24T13:22:16.640186Z"
        },
        "trusted": true,
        "id": "Z_6CJA62pDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "sJ6jsDb0pDmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "input_image = \"/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/002.jpg\"\n",
        "out = model.predict_segmentation(\n",
        "    inp=input_image,\n",
        "    out_fname=\"out.png\"\n",
        ")\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 20), constrained_layout=True)\n",
        "\n",
        "img_orig = Image.open(input_image)\n",
        "axs[0].imshow(img_orig)\n",
        "axs[0].set_title('original image-002.jpg')\n",
        "axs[0].grid(False)\n",
        "\n",
        "axs[1].imshow(out)\n",
        "axs[1].set_title('prediction image-out.png')\n",
        "axs[1].grid(False)\n",
        "\n",
        "validation_image = \"/kaggle/input/semantic-drone-dataset/dataset/dataset/semantic_drone_dataset/label_images_semantic/002.png\"\n",
        "axs[2].imshow( Image.open(validation_image))\n",
        "axs[2].set_title('true label image-002.png')\n",
        "axs[2].grid(False)\n",
        "\n",
        "\n",
        "done = time.time()\n",
        "elapsed = done - start"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T13:22:16.644135Z",
          "iopub.execute_input": "2024-03-24T13:22:16.644493Z",
          "iopub.status.idle": "2024-03-24T13:22:21.622422Z",
          "shell.execute_reply.started": "2024-03-24T13:22:16.644426Z",
          "shell.execute_reply": "2024-03-24T13:22:21.620796Z"
        },
        "trusted": true,
        "id": "TqStwv2spDmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(elapsed)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T13:22:21.623731Z",
          "iopub.status.idle": "2024-03-24T13:22:21.624309Z"
        },
        "trusted": true,
        "id": "eImjrGZ5pDmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}